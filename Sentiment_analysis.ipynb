{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMatDlQ82PP8TvDPIB5+IO6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shanmugapriya-Karthikumar/Sentiment_Analyzer/blob/main/Sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests feedparser pandas python-dotenv google-generativeai tqdm matplotlib prophet scipy textblob schedule streamlit numpy plotly pyngrok"
      ],
      "metadata": {
        "id": "21t7o7LRiJgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37bd558-0745-4286-9b16-df64ab133801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: prophet in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.183.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from prophet) (1.2.5)\n",
            "Requirement already satisfied: holidays<1,>=0.25 in /usr/local/lib/python3.12/dist-packages (from prophet) (0.81)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from prophet) (6.5.2)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n",
            "Requirement already satisfied: stanio<2.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.5.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.4.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=605dd00bf3bff0df71276fc50deb2fb958795817b2096063029ada5391084da4\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, schedule, pyngrok, feedparser, pydeck, streamlit\n",
            "Successfully installed feedparser-6.0.12 pydeck-0.9.1 pyngrok-7.4.0 schedule-1.2.2 sgmllib3k-1.0.0 streamlit-1.50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prophet import Prophet\n",
        "import os\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from scipy import stats\n",
        "\n",
        "# Custom CSS for a polished, professional dashboard\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main-header {\n",
        "        font-size: 2.5rem;\n",
        "        color: #1E3A8A;\n",
        "        text-align: center;\n",
        "        margin-bottom: 1.5rem;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .sub-header {\n",
        "        font-size: 1.8rem;\n",
        "        color: #3B82F6;\n",
        "        margin-top: 1rem;\n",
        "        margin-bottom: 1rem;\n",
        "    }\n",
        "    .metric-card {\n",
        "        background-color: #F8FAFC;\n",
        "        padding: 1.2rem;\n",
        "        border-radius: 8px;\n",
        "        box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
        "        text-align: center;\n",
        "        margin: 0.5rem;\n",
        "        border-left: 4px solid #3B82F6;\n",
        "    }\n",
        "    .metric-title {\n",
        "        font-size: 1.1rem;\n",
        "        color: #4B5563;\n",
        "        margin-bottom: 0.5rem;\n",
        "    }\n",
        "    .metric-value {\n",
        "        font-size: 1.5rem;\n",
        "        color: #1E3A8A;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .alert-box {\n",
        "        background-color: #FEF2F2;\n",
        "        padding: 1rem;\n",
        "        border-radius: 8px;\n",
        "        border-left: 4px solid #EF4444;\n",
        "        margin: 0.5rem 0;\n",
        "    }\n",
        "    .success-box {\n",
        "        background-color: #ECFDF5;\n",
        "        padding: 1rem;\n",
        "        border-radius: 8px;\n",
        "        border-left: 4px solid #10B981;\n",
        "        margin: 0.5rem 0;\n",
        "    }\n",
        "    .placeholder-text {\n",
        "        color: #6B7280;\n",
        "        text-align: center;\n",
        "        font-style: italic;\n",
        "    }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Thresholds\n",
        "THRESHOLDS = {\n",
        "    'sentiment_drop': -0.1,\n",
        "    'surge_zscore': 1.0\n",
        "}\n",
        "\n",
        "# Sample data for testing (varied sentiment for non-linear plots)\n",
        "SAMPLE_DATA = pd.DataFrame({\n",
        "    \"topic\": [\"AI\"] * 20 + [\"Cloud Computing\"] * 20 + [\"Cybersecurity\"] * 20,\n",
        "    \"publishedAt\": pd.date_range(start=\"2025-09-28\", end=\"2025-10-07\", periods=20).tolist() * 3,\n",
        "    \"sentiment_score\": [\n",
        "        0.2, -0.1, 0.3, -0.05, 0.15, -0.2, 0.25, 0.0, -0.15, 0.1,\n",
        "        0.3, -0.2, 0.1, -0.1, 0.2, -0.05, 0.25, -0.1, 0.15, 0.0\n",
        "    ] * 3,\n",
        "    \"title\": [\"Sample Article\"] * 60\n",
        "})\n",
        "\n",
        "# Function Definitions\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text by removing special characters and extra spaces.\"\"\"\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return ' '.join(text.split())\n",
        "\n",
        "def run_pipeline(topics):\n",
        "    \"\"\"Fetch and process news for given topics using NewsAPI and TextBlob for sentiment.\"\"\"\n",
        "    api_key = os.getenv(\"NEWS_API_KEY\")\n",
        "    if not api_key:\n",
        "        st.markdown('<div class=\"alert-box\">‚ö†Ô∏è NewsAPI key is missing. Using sample data.</div>', unsafe_allow_html=True)\n",
        "        return SAMPLE_DATA\n",
        "\n",
        "    all_data = []\n",
        "    for topic in topics:\n",
        "        url = \"https://newsapi.org/v2/everything\"\n",
        "        params = {\n",
        "            \"q\": topic,\n",
        "            \"pageSize\": 100,\n",
        "            \"apiKey\": api_key,\n",
        "            \"language\": \"en\",\n",
        "            \"sortBy\": \"publishedAt\",\n",
        "            \"from\": (datetime.now() - timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
        "        }\n",
        "        try:\n",
        "            response = requests.get(url, params=params)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            articles = data.get(\"articles\", [])\n",
        "            if articles:\n",
        "                df = pd.DataFrame(articles)\n",
        "                df[\"topic\"] = topic\n",
        "                df[\"publishedAt\"] = pd.to_datetime(df[\"publishedAt\"], errors=\"coerce\")\n",
        "                df[\"clean_text\"] = (df[\"title\"].fillna(\"\") + \" \" + df[\"description\"].fillna(\"\")).apply(clean_text)\n",
        "                sentiments = [(TextBlob(text).sentiment.polarity, text) for text in df[\"clean_text\"]]\n",
        "                df[\"sentiment_score\"] = [score for score, _ in sentiments]\n",
        "                all_data.append(df[[\"topic\", \"publishedAt\", \"sentiment_score\", \"title\"]])\n",
        "            else:\n",
        "                st.markdown(f'<div class=\"alert-box\">‚ö†Ô∏è No articles found for topic: {topic}</div>', unsafe_allow_html=True)\n",
        "        except Exception as e:\n",
        "            st.markdown(f'<div class=\"alert-box\">‚ö†Ô∏è Error fetching news for {topic}: {str(e)}. Using sample data.</div>', unsafe_allow_html=True)\n",
        "            return SAMPLE_DATA\n",
        "\n",
        "    if all_data:\n",
        "        combined_df = pd.concat(all_data, ignore_index=True)\n",
        "        st.markdown(f'<div class=\"success-box\">üì• Fetched {len(combined_df)} articles</div>', unsafe_allow_html=True)\n",
        "        return combined_df\n",
        "    st.markdown('<div class=\"alert-box\">‚ö†Ô∏è No data fetched. Using sample data.</div>', unsafe_allow_html=True)\n",
        "    return SAMPLE_DATA\n",
        "\n",
        "def forecast_sentiment(trend_data, keyword, days=7):\n",
        "    \"\"\"Forecast sentiment trends using Prophet.\"\"\"\n",
        "    try:\n",
        "        sub_df = trend_data[trend_data[\"keyword\"] == keyword][[\"date\", \"sentiment_score\"]].rename(columns={\"date\": \"ds\", \"sentiment_score\": \"y\"})\n",
        "        sub_df[\"ds\"] = pd.to_datetime(sub_df[\"ds\"])\n",
        "        if len(sub_df) < 3:\n",
        "            st.markdown(f'<div class=\"alert-box\">‚ö†Ô∏è Insufficient data for {keyword}: {len(sub_df)} points (need at least 3)</div>', unsafe_allow_html=True)\n",
        "            return None, pd.DataFrame()\n",
        "        model = Prophet(yearly_seasonality=False, weekly_seasonality=True, daily_seasonality=True)\n",
        "        model.fit(sub_df)\n",
        "        future = model.make_future_dataframe(periods=days, freq=\"H\")\n",
        "        forecast = model.predict(future)\n",
        "        return model, forecast\n",
        "    except Exception as e:\n",
        "        st.markdown(f'<div class=\"alert-box\">‚ö†Ô∏è Forecasting failed for {keyword}: {str(e)}</div>', unsafe_allow_html=True)\n",
        "        return None, pd.DataFrame()\n",
        "\n",
        "def check_alerts(trend_data, thresholds, slack_webhook=None):\n",
        "    \"\"\"Check for sentiment and volume anomalies.\"\"\"\n",
        "    alerts = []\n",
        "    st.markdown('<h2 class=\"sub-header\">üîç Alerts</h2>', unsafe_allow_html=True)\n",
        "    if trend_data.empty:\n",
        "        st.markdown('<div class=\"alert-box\">‚ö†Ô∏è No data to analyze for alerts</div>', unsafe_allow_html=True)\n",
        "        return alerts\n",
        "    for kw in trend_data[\"keyword\"].unique():\n",
        "        sub_df = trend_data[trend_data[\"keyword\"] == kw]\n",
        "        if len(sub_df) < 2:\n",
        "            for _, row in sub_df.iterrows():\n",
        "                if row[\"sentiment_score\"] < thresholds[\"sentiment_drop\"]:\n",
        "                    alert = f\"Sentiment drop for {kw} on {row['date'].strftime('%Y-%m-%d %H:%M')}: {row['sentiment_score']:.2f}\"\n",
        "                    alerts.append(alert)\n",
        "                    st.markdown(f'<div class=\"alert-box\">{alert}</div>', unsafe_allow_html=True)\n",
        "            continue\n",
        "        z_scores = stats.zscore(sub_df[\"sentiment_score\"], nan_policy=\"omit\")\n",
        "        for i, row in sub_df.iterrows():\n",
        "            if row[\"sentiment_score\"] < thresholds[\"sentiment_drop\"]:\n",
        "                alert = f\"Sentiment drop for {kw} on {row['date'].strftime('%Y-%m-%d %H:%M')}: {row['sentiment_score']:.2f}\"\n",
        "                alerts.append(alert)\n",
        "                st.markdown(f'<div class=\"alert-box\">{alert}</div>', unsafe_allow_html=True)\n",
        "            if i < len(z_scores) and abs(z_scores[i]) > thresholds[\"surge_zscore\"]:\n",
        "                alert = f\"Surge anomaly for {kw} on {row['date'].strftime('%Y-%m-%d %H:%M')}: z-score {z_scores[i]:.2f}\"\n",
        "                alerts.append(alert)\n",
        "                st.markdown(f'<div class=\"alert-box\">{alert}</div>', unsafe_allow_html=True)\n",
        "\n",
        "    if alerts and slack_webhook:\n",
        "        try:\n",
        "            payload = {\"text\": \"\\n\".join(alerts)}\n",
        "            response = requests.post(slack_webhook, json=payload)\n",
        "            response.raise_for_status()\n",
        "            st.markdown('<div class=\"success-box\">‚úÖ Alerts sent to Slack</div>', unsafe_allow_html=True)\n",
        "        except Exception as e:\n",
        "            st.markdown(f'<div class=\"alert-box\">‚ö†Ô∏è Failed to send Slack alerts: {str(e)}</div>', unsafe_allow_html=True)\n",
        "\n",
        "    if not alerts:\n",
        "        st.markdown('<div class=\"success-box\">‚úÖ No alerts triggered</div>', unsafe_allow_html=True)\n",
        "\n",
        "    return alerts\n",
        "\n",
        "def load_historical_data():\n",
        "    \"\"\"Load historical data from session state.\"\"\"\n",
        "    return st.session_state.get(\"historical_df\", pd.DataFrame())\n",
        "\n",
        "def save_updated_history(combined_df):\n",
        "    \"\"\"Save combined data to session state.\"\"\"\n",
        "    st.session_state.historical_df = combined_df\n",
        "    st.markdown(f'<div class=\"success-box\">üíæ Updated history with {len(combined_df)} data points</div>', unsafe_allow_html=True)\n",
        "\n",
        "def process_new_data(new_df):\n",
        "    \"\"\"Process and normalize new data.\"\"\"\n",
        "    if new_df.empty:\n",
        "        st.markdown('<div class=\"alert-box\">‚ö†Ô∏è No new data to process</div>', unsafe_allow_html=True)\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    new_df[\"date\"] = pd.to_datetime(new_df[\"publishedAt\"], errors=\"coerce\").dt.tz_localize(None)\n",
        "    new_df = new_df.dropna(subset=[\"date\"])\n",
        "\n",
        "    new_trend = (\n",
        "        new_df.groupby([\"topic\", pd.Grouper(key=\"date\", freq=\"H\")])\n",
        "        .agg(\n",
        "            avg_sentiment=(\"sentiment_score\", \"mean\"),\n",
        "            articles_count=(\"sentiment_score\", \"count\")\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    new_trend = new_trend.rename(columns={\n",
        "        \"topic\": \"keyword\",\n",
        "        \"avg_sentiment\": \"sentiment_score\"\n",
        "    })\n",
        "\n",
        "    return new_trend\n",
        "\n",
        "def combine_data(historical_df, new_trend):\n",
        "    \"\"\"Combine historical and new data.\"\"\"\n",
        "    if not historical_df.empty:\n",
        "        combined_df = pd.concat([historical_df, new_trend], ignore_index=True)\n",
        "        combined_df = combined_df.drop_duplicates(subset=[\"keyword\", \"date\"], keep=\"last\")\n",
        "        combined_df = combined_df.sort_values([\"keyword\", \"date\"])\n",
        "    else:\n",
        "        combined_df = new_trend\n",
        "\n",
        "    save_updated_history(combined_df)\n",
        "    return combined_df\n",
        "\n",
        "def plot_trend(keyword, data):\n",
        "    \"\"\"Plot sentiment trend for a keyword using Plotly.\"\"\"\n",
        "    if data.empty:\n",
        "        st.markdown(f'<div class=\"alert-box\">‚ö†Ô∏è No data available for {keyword}</div>', unsafe_allow_html=True)\n",
        "        return\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=data[\"date\"],\n",
        "        y=data[\"sentiment_score\"],\n",
        "        mode=\"lines+markers\",\n",
        "        line=dict(color=\"#1E3A8A\", width=2),\n",
        "        marker=dict(size=8, color=\"#3B82F6\"),\n",
        "        name=\"Sentiment\",\n",
        "        hovertemplate=\"Date: %{x}<br>Sentiment: %{y:.2f}<extra></extra>\"\n",
        "    ))\n",
        "\n",
        "    fig.add_hline(y=0, line_dash=\"solid\", line_color=\"gray\", line_width=1, opacity=0.5)\n",
        "    fig.add_hline(y=0.3, line_dash=\"dot\", line_color=\"green\", line_width=1, opacity=0.7)\n",
        "    fig.add_hline(y=-0.3, line_dash=\"dot\", line_color=\"red\", line_width=1, opacity=0.7)\n",
        "\n",
        "    avg_sentiment = data[\"sentiment_score\"].mean()\n",
        "    latest_sentiment = data[\"sentiment_score\"].iloc[-1]\n",
        "    stats_text = f\"Average: {avg_sentiment:.2f}<br>Latest: {latest_sentiment:.2f}\"\n",
        "\n",
        "    fig.add_annotation(\n",
        "        xref=\"paper\", yref=\"paper\", x=0.02, y=0.98,\n",
        "        text=stats_text, showarrow=False, align=\"left\",\n",
        "        bgcolor=\"lightblue\", bordercolor=\"gray\", borderwidth=1,\n",
        "        font=dict(size=12)\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"Sentiment Trend: {keyword}\",\n",
        "        title_font=dict(size=20, color=\"#1E3A8A\", family=\"Arial\"),\n",
        "        xaxis_title=\"Date\",\n",
        "        yaxis_title=\"Average Sentiment Score\",\n",
        "        xaxis=dict(tickangle=45, gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "        yaxis=dict(gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "        plot_bgcolor=\"white\",\n",
        "        showlegend=True,\n",
        "        margin=dict(t=50, b=50),\n",
        "        hovermode=\"x unified\"\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "def plot_forecast(keyword, trend_data, forecast_data):\n",
        "    \"\"\"Plot forecast for a keyword using Plotly.\"\"\"\n",
        "    if forecast_data.empty:\n",
        "        st.markdown(f'<div class=\"alert-box\">‚ö†Ô∏è No forecast data for {keyword}</div>', unsafe_allow_html=True)\n",
        "        return\n",
        "\n",
        "    historical_data = trend_data[trend_data[\"keyword\"] == keyword].copy()\n",
        "    historical_data = historical_data.sort_values(\"date\")\n",
        "    forecast_start_date = historical_data[\"date\"].max()\n",
        "    future_forecast = forecast_data[forecast_data[\"ds\"] > forecast_start_date]\n",
        "\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Historical data\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=historical_data[\"date\"],\n",
        "        y=historical_data[\"sentiment_score\"],\n",
        "        mode=\"lines+markers\",\n",
        "        line=dict(color=\"#1E3A8A\", width=2),\n",
        "        marker=dict(size=6, color=\"#3B82F6\"),\n",
        "        name=\"Historical Data\",\n",
        "        hovertemplate=\"Date: %{x}<br>Sentiment: %{y:.2f}<extra></extra>\"\n",
        "    ))\n",
        "\n",
        "    # Forecast data\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=future_forecast[\"ds\"],\n",
        "        y=future_forecast[\"yhat\"],\n",
        "        mode=\"lines+markers\",\n",
        "        line=dict(color=\"#EF4444\", width=2),\n",
        "        marker=dict(size=6, color=\"#F87171\"),\n",
        "        name=\"7-Day Forecast\",\n",
        "        hovertemplate=\"Date: %{x}<br>Forecast: %{y:.2f}<extra></extra>\"\n",
        "    ))\n",
        "\n",
        "    # Confidence interval\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=future_forecast[\"ds\"].tolist() + future_forecast[\"ds\"][::-1].tolist(),\n",
        "        y=future_forecast[\"yhat_upper\"].tolist() + future_forecast[\"yhat_lower\"][::-1].tolist(),\n",
        "        fill=\"toself\",\n",
        "        fillcolor=\"rgba(239, 68, 68, 0.15)\",\n",
        "        line=dict(color=\"rgba(0,0,0,0)\"),  # Fixed: Use rgba for transparent line\n",
        "        name=\"Confidence Interval\",\n",
        "        hoverinfo=\"skip\"\n",
        "    ))\n",
        "\n",
        "    fig.add_hline(y=0, line_dash=\"solid\", line_color=\"gray\", line_width=1, opacity=0.6)\n",
        "    fig.add_hline(y=0.3, line_dash=\"dot\", line_color=\"green\", line_width=1, opacity=0.5)\n",
        "    fig.add_hline(y=-0.3, line_dash=\"dot\", line_color=\"red\", line_width=1, opacity=0.5)\n",
        "    fig.add_vline(x=forecast_start_date, line_dash=\"dash\", line_color=\"gray\", line_width=1, opacity=0.6)\n",
        "\n",
        "    avg_historical = historical_data[\"sentiment_score\"].mean()\n",
        "    latest_sentiment = historical_data[\"sentiment_score\"].iloc[-1]\n",
        "    forecast_avg = future_forecast[\"yhat\"].mean() if not future_forecast.empty else 0\n",
        "    forecast_trend = \"‚Üó Improving\" if future_forecast[\"yhat\"].iloc[-1] > future_forecast[\"yhat\"].iloc[0] else \"‚Üò Declining\" if not future_forecast.empty else \"N/A\"\n",
        "\n",
        "    stats_text = f\"Historical Avg: {avg_historical:.2f}<br>Latest: {latest_sentiment:.2f}<br>Forecast Avg: {forecast_avg:.2f}<br>Trend: {forecast_trend}\"\n",
        "\n",
        "    fig.add_annotation(\n",
        "        xref=\"paper\", yref=\"paper\", x=0.02, y=0.98,\n",
        "        text=stats_text, showarrow=False, align=\"left\",\n",
        "        bgcolor=\"white\", bordercolor=\"gray\", borderwidth=1,\n",
        "        font=dict(size=12)\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"Sentiment Forecast: {keyword}\",\n",
        "        title_font=dict(size=20, color=\"#1E3A8A\", family=\"Arial\"),\n",
        "        xaxis_title=\"Date\",\n",
        "        yaxis_title=\"Sentiment Score\",\n",
        "        xaxis=dict(tickangle=45, gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "        yaxis=dict(gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "        plot_bgcolor=\"white\",\n",
        "        showlegend=True,\n",
        "        margin=dict(t=50, b=50),\n",
        "        hovermode=\"x unified\"\n",
        "    )\n",
        "\n",
        "    st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "# Streamlit App\n",
        "st.set_page_config(page_title=\"Real-Time Industry Insights\", layout=\"wide\", page_icon=\"üìä\")\n",
        "st.markdown('<h1 class=\"main-header\">üìä Real-Time Industry Insights</h1>', unsafe_allow_html=True)\n",
        "st.markdown(f'<p style=\"text-align: center; color: #6B7280;\">Last updated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}</p>', unsafe_allow_html=True)\n",
        "\n",
        "# Placeholder if no data\n",
        "st.markdown('<p class=\"placeholder-text\">Enter your NewsAPI key and topics to get started.</p>', unsafe_allow_html=True)\n",
        "\n",
        "# API Key and Topic Input\n",
        "col1, col2 = st.columns([1, 1])\n",
        "with col1:\n",
        "    news_api_key = st.text_input(\"üîë NewsAPI Key\", type=\"password\", help=\"Get a free key from newsapi.org\")\n",
        "    if news_api_key:\n",
        "        os.environ[\"NEWS_API_KEY\"] = news_api_key\n",
        "with col2:\n",
        "    topics_input = st.text_input(\"üîç Topics (comma-separated)\", value=\"AI, Cloud Computing, Cybersecurity\", help=\"Enter topics to analyze\")\n",
        "    topics = [t.strip() for t in topics_input.split(\",\") if t.strip()]\n",
        "\n",
        "# Slack Webhook (Optional)\n",
        "slack_webhook = st.text_input(\"üì¢ Slack Webhook URL (Optional)\", type=\"password\", help=\"Enter Slack webhook for alerts\")\n",
        "\n",
        "# Fetch and Process Data\n",
        "if st.button(\"üöÄ Fetch and Analyze Data\", key=\"fetch_data_button\"):\n",
        "    if not topics:\n",
        "        st.markdown('<div class=\"alert-box\">‚ö†Ô∏è Please enter at least one topic</div>', unsafe_allow_html=True)\n",
        "    else:\n",
        "        with st.spinner(\"Fetching and analyzing data...\"):\n",
        "            new_df = run_pipeline(topics)\n",
        "            if not new_df.empty:\n",
        "                new_trend = process_new_data(new_df)\n",
        "                historical_df = load_historical_data()\n",
        "                trend_data = combine_data(historical_df, new_trend)\n",
        "\n",
        "                # Display Metrics\n",
        "                st.markdown('<h2 class=\"sub-header\">üìà Key Metrics</h2>', unsafe_allow_html=True)\n",
        "                cols = st.columns(3)\n",
        "                total_articles = len(new_df)\n",
        "                avg_sentiment = new_trend[\"sentiment_score\"].mean() if not new_trend.empty else 0\n",
        "                unique_keywords = len(new_trend[\"keyword\"].unique()) if not new_trend.empty else 0\n",
        "                with cols[0]:\n",
        "                    st.markdown(f'<div class=\"metric-card\"><div class=\"metric-title\">Total Articles</div><div class=\"metric-value\">{total_articles}</div></div>', unsafe_allow_html=True)\n",
        "                with cols[1]:\n",
        "                    st.markdown(f'<div class=\"metric-card\"><div class=\"metric-title\">Avg. Sentiment</div><div class=\"metric-value\">{avg_sentiment:.2f}</div></div>', unsafe_allow_html=True)\n",
        "                with cols[2]:\n",
        "                    st.markdown(f'<div class=\"metric-card\"><div class=\"metric-title\">Keywords Analyzed</div><div class=\"metric-value\">{unique_keywords}</div></div>', unsafe_allow_html=True)\n",
        "\n",
        "                # Check Alerts\n",
        "                alerts = check_alerts(trend_data, THRESHOLDS, slack_webhook)\n",
        "\n",
        "                # Display Trends and Forecasts\n",
        "                for keyword in trend_data[\"keyword\"].unique():\n",
        "                    st.markdown(f'<h2 class=\"sub-header\">üìä {keyword} Analysis</h2>', unsafe_allow_html=True)\n",
        "                    keyword_data = trend_data[trend_data[\"keyword\"] == keyword]\n",
        "                    plot_trend(keyword, keyword_data)\n",
        "\n",
        "                    model, forecast = forecast_sentiment(trend_data, keyword)\n",
        "                    if model is not None and not forecast.empty:\n",
        "                        plot_forecast(keyword, trend_data, forecast)\n",
        "            else:\n",
        "                st.markdown('<div class=\"alert-box\">‚ö†Ô∏è Failed to fetch data. Please check your API key or try different topics.</div>', unsafe_allow_html=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAkE7CYBQUbQ",
        "outputId": "3f5e2f43-96b4-4a98-820e-4d32c8c9aa5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ngrok Setup\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Terminate any existing tunnels\n",
        "!pkill ngrok\n",
        "!pkill streamlit\n",
        "\n",
        "# Set your ngrok auth token\n",
        "ngrok.set_auth_token(\"33ecwoVtWHx4LX5H0WV9iltadAH_2PsiQGEjBE9V7KP6Hkp9P\")  # Replace with your token\n",
        "\n",
        "# Start Streamlit server\n",
        "os.system(\"streamlit run app.py &\")\n",
        "\n",
        "# Create a public URL with ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit app is live at:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LrOa1ISP5Iy",
        "outputId": "809450aa-9258-4ebe-ed5c-1903486b1e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://resistantly-spiritlike-irina.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}